# AI Speech Evaluator - Sistema di Valutazione Presentazioni üéØ

Un sistema **completamente locale** e **operativo** di valutazione speech-to-text basato su RAG (Retrieval-Augmented Generation) che analizza presentazioni orali confrontandole con documenti di riferimento utilizzando **Ollama** e **Whisper locale**.

**üöÄ STATUS: PIENAMENTE FUNZIONANTE** - Sistema testato e operativo per il flusso completo: Upload ‚Üí Registrazione ‚Üí Trascrizione ‚Üí Valutazione AI

## üåü Caratteristiche Principali

### üîí **100% Privacy & Controllo Locale**
- **Nessuna dipendenza da API esterne** - Tutto eseguito localmente
- **Privacy totale** - I dati non lasciano mai il tuo server
- **Costi zero** - Nessun costo per API calls
- **Controllo completo** - Modelli e configurazioni personalizzabili

### üöÄ **Funzionalit√† Complete (100% Operative)**
- ‚úÖ **Upload Documenti Multi-formato**: PDF, DOCX, TXT con drag & drop
- ‚úÖ **Registrazione Audio Professionale**: Waveform real-time e controlli avanzati
- ‚úÖ **Speech-to-Text Locale**: Trascrizione Whisper completamente configurata
- ‚úÖ **Sistema RAG Intelligente**: Embedding e similarity search con Ollama
- ‚úÖ **Valutazione AI Completa**: Scoring multi-criterio con feedback dettagliato
- ‚úÖ **Interfaccia Moderna**: Design responsive con Tailwind CSS
- ‚úÖ **Architettura Professionale**: Middleware di sicurezza, logging, rate limiting
- ‚úÖ **Gestione Automatica Porte**: Cleanup automatico per evitare conflitti

## üèóÔ∏è Architettura

```
ai-speech-evaluator/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ frontend/          # Next.js React app
‚îÇ   ‚îî‚îÄ‚îÄ backend/           # Express.js API server
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ shared/            # Tipi e schemi condivisi
‚îÇ   ‚îú‚îÄ‚îÄ database/          # Prisma ORM e migrations
‚îÇ   ‚îú‚îÄ‚îÄ ai-services/       # Servizi AI e RAG
‚îÇ   ‚îî‚îÄ‚îÄ audio-services/    # Servizi audio e trascrizione
‚îú‚îÄ‚îÄ docs/                  # Documentazione
‚îî‚îÄ‚îÄ scripts/               # Utility scripts
```

## üõ†Ô∏è Stack Tecnologico

### Frontend
- **Next.js 14** - React framework con App Router
- **TypeScript** - Type safety completo
- **Tailwind CSS** - Styling moderno e responsive
- **React Dropzone** - File upload con drag & drop
- **MediaRecorder API** - Registrazione audio nativa
- **AudioContext API** - Analisi audio real-time
- **Canvas API** - Visualizzazione waveform
- **Lucide React** - Icons moderni

### Backend
- **Express.js** - Web server con middleware enterprise
- **TypeScript** - Type safety completo
- **Multer** - File upload sicuro
- **Winston** - Logging professionale
- **Helmet** - Security headers
- **Express Rate Limit** - Rate limiting granulare
- **Express Validator** - Validazione input robusta

### ü§ñ **AI & ML Locale (Configurato e Testato)**
- **Ollama** ‚úÖ - LLM locale (Llama 3.2:3b, Qwen, ecc.)
- **OpenAI Whisper** ‚úÖ - Speech-to-text locale con modello base precaricato
- **Vector Store** ‚úÖ - Similarity search in-memory o Pinecone
- **Custom RAG Pipeline** ‚úÖ - Implementazione RAG ottimizzata e testata
- **Embedding Locale** ‚úÖ - Nomic Embed Text via Ollama (768 dimensioni)

## üöÄ Quick Start

### Prerequisiti (Obbligatori)
- **Node.js 18+** ‚úÖ - Runtime JavaScript
- **Python 3.8+** ‚úÖ - Per OpenAI Whisper
- **Ollama** ‚úÖ - Server LLM locale ([Installa qui](https://ollama.ai))
- **Browser moderno** ‚úÖ - Con supporto MediaRecorder API

### Prerequisiti Opzionali
- **PostgreSQL** - Per storage persistente (futuro)
- **Pinecone** - Per vector database cloud (opzionale)
- **Docker** - Per deployment containerizzato

### üîß Installazione

#### 1. **Setup Ollama (Obbligatorio)**
```bash
# Installa Ollama dal sito ufficiale
curl -fsSL https://ollama.ai/install.sh | sh

# Avvia il server Ollama
ollama serve

# In un nuovo terminale, scarica i modelli richiesti
ollama pull llama3.2:3b          # Modello LLM principale
ollama pull nomic-embed-text     # Modello per embeddings
```

#### 2. **Setup OpenAI Whisper (Obbligatorio)**
```bash
# Installa OpenAI Whisper per trascrizione locale
pip3 install openai-whisper

# Verifica installazione
whisper --help

# Il modello 'base' verr√† scaricato automaticamente al primo uso
# Puoi pre-scaricare il modello per evitare latenza:
python3 -c "import whisper; whisper.load_model('base')"
```

#### 3. **Clone e Setup Progetto**
```bash
# Clone repository
git clone https://github.com/simo-hue/AI-RAG-Tutor.git
cd AI-RAG-Tutor

# Installa dipendenze
npm install

# Configura environment dal template
cp apps/backend/.env.example apps/backend/.env
```

#### 4. **Configurazione Base (.env)**
```bash
# File: apps/backend/.env
NODE_ENV=development
PORT=3002

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Vector Database (memory per sviluppo)
VECTOR_DB_TYPE=memory
EMBEDDING_DIMENSIONS=768

# File Storage
UPLOAD_DIR=./uploads

# CORS
FRONTEND_URL=http://localhost:3000
```

#### 5. **Avvia Applicazione**
```bash
# Avvia entrambi i servizi contemporaneamente
npm run dev

# Oppure separatamente:
npm run dev:frontend    # Frontend su porta 3000
npm run dev:backend     # Backend su porta 3002
```

### ‚úÖ **Verifica Setup**
1. **Frontend**: http://localhost:3000
2. **Backend Health**: http://localhost:3002/api/health
3. **Ollama Status**: http://localhost:11434/api/tags
4. **Whisper Test**: `whisper --help` (deve mostrare help senza errori)

### üîß **Troubleshooting Comuni**

#### Errore EADDRINUSE (Porta gi√† in uso)
```bash
# Il sistema include cleanup automatico, ma in caso di problemi:
npm run restart        # Cleanup automatico e restart
# oppure manualmente:
npm run kill-ports     # Kill processi su porte 3000,3002
```

#### Errore Whisper SSL/Certificati
```bash
# Se Whisper non riesce a scaricare modelli:
python3 -c "
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
import whisper
whisper.load_model('base')
"
```

#### Ollama non risponde
```bash
# Riavvia Ollama
pkill ollama
ollama serve

# Verifica modelli installati
ollama list
```

## üéØ **Funzionalit√† Complete Disponibili**

### ‚úÖ **Sistema RAG Completo**
- **Upload Documenti**: PDF, DOCX, TXT con validazione
- **Document Processing**: Parsing, chunking e generazione embeddings
- **Vector Search**: Similarity search contestuale con Ollama
- **Context Retrieval**: Recupero chunks rilevanti per valutazione

### ‚úÖ **Registrazione e Trascrizione**
- **Audio Recording**: Registrazione browser con waveform real-time
- **Speech-to-Text**: Trascrizione locale con Whisper (no API esterne)
- **Audio Processing**: Gestione formati multipli e validazione

### ‚úÖ **Valutazione AI Avanzata**
- **Evaluation Engine**: Valutazione multi-criterio con Ollama
- **Scoring System**: Accuracy, Clarity, Completeness, Coherence, Fluency
- **Detailed Feedback**: Feedback dettagliato con suggerimenti miglioramento
- **Batch Processing**: Valutazione multipla e confronto presentazioni

### ‚úÖ **Sicurezza e Monitoring**
- **Rate Limiting**: Limiti granulari per tipo di operazione
- **Input Validation**: Validazione robusta con express-validator
- **Security Headers**: Protezione completa con Helmet
- **Structured Logging**: Logging professionale con Winston
- **Health Checks**: Monitoring servizi AI e database

## üìä **Flusso Operativo Completo**

### Pipeline Implementata üöÄ
```
1. Upload Documento ‚Üí Validazione ‚Üí Parsing
                                     ‚Üì
2. Chunking Intelligente ‚Üí Embedding Generation (Ollama)
                                     ‚Üì
3. Vector Storage ‚Üí Similarity Index ‚Üí Ready for Query
                                     ‚Üì
4. Audio Recording ‚Üí Local Transcription (Whisper)
                                     ‚Üì
5. Context Retrieval ‚Üí RAG Query ‚Üí Relevant Chunks
                                     ‚Üì
6. AI Evaluation (Ollama) ‚Üí Multi-Criteria Scoring
                                     ‚Üì
7. Detailed Feedback ‚Üí Recommendations ‚Üí Final Report
```

## ‚öôÔ∏è **Configurazione Avanzata**

### üîß **Backend Environment (apps/backend/.env)**

#### Configurazione Base (Obbligatoria)
```env
# Server Configuration
NODE_ENV=development
PORT=3001

# Ollama LLM Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_TIMEOUT=120000

# Vector Database
VECTOR_DB_TYPE=memory                # 'memory' o 'pinecone'
EMBEDDING_DIMENSIONS=768
EMBEDDING_BATCH_SIZE=5

# Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
PRESERVE_SENTENCES=true

# File Storage
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=50
```

#### Configurazione Avanzata (Opzionale)
```env
# Whisper Local (Trascrizione)
WHISPER_MODEL_PATH=./models/whisper
WHISPER_MODEL=base
WHISPER_LANGUAGE=auto

# Security & CORS
FRONTEND_URL=http://localhost:3000
LOG_LEVEL=info

# Rate Limiting (Personalizzabile)
EVALUATION_RATE_LIMIT=20            # Valutazioni per ora
UPLOAD_RATE_LIMIT=10                # Upload per ora
TRANSCRIPTION_RATE_LIMIT=30         # Trascrizioni per ora

# Pinecone (Solo se VECTOR_DB_TYPE=pinecone)
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENVIRONMENT=gcp-starter
PINECONE_INDEX_NAME=ai-speech-evaluator
```

### üéöÔ∏è **Modelli Supportati**

#### LLM Models (via Ollama)
```bash
# Modelli raccomandati per qualit√†/performance
ollama pull llama3.2:3b         # Veloce, buona qualit√†
ollama pull llama3.2:7b         # Migliore qualit√†, pi√π lento
ollama pull qwen2.5:7b          # Alternativa high-quality
ollama pull mistral:7b          # Buono per evaluazioni
```

#### Embedding Models
```bash
ollama pull nomic-embed-text    # Raccomandato (768 dim)
ollama pull mxbai-embed-large   # Alta qualit√† (1024 dim)
```

#### Whisper Models (Locale)
- **tiny**: Velocissimo, qualit√† base
- **base**: Bilanciato (raccomandato)
- **small**: Qualit√† migliore
- **medium**: Alta qualit√†, pi√π lento

## üìö **API Endpoints Completi**

### üìÑ **Documenti RAG**
```http
POST   /api/documents/upload                    # Upload documento con processing
GET    /api/documents/                          # Lista documenti
GET    /api/documents/:id                       # Dettagli documento
DELETE /api/documents/:id                       # Elimina documento
GET    /api/documents/:id/status                # Stato processing
POST   /api/documents/:id/process               # Riprocessa documento
POST   /api/documents/:documentId/search        # Similarity search
POST   /api/documents/:documentId/relevant-context  # Context per valutazione
GET    /api/documents/:id/chunks                # Visualizza chunks
GET    /api/documents/:id/metadata              # Metadata documento
```

### üéµ **Audio e Trascrizione**
```http
POST   /api/audio/upload                        # Upload audio
POST   /api/audio/:id/transcribe                # Trascrizione locale
GET    /api/audio/:id                           # Dettagli registrazione
DELETE /api/audio/:id                           # Elimina registrazione
GET    /api/audio/document/:documentId          # Audio per documento
GET    /api/audio/:id/status                    # Stato processing
```

### üéØ **Valutazione AI**
```http
POST   /api/evaluations/evaluate                # Valutazione completa
POST   /api/evaluations/quick                   # Valutazione rapida
POST   /api/evaluations/detailed-feedback       # Feedback dettagliato
POST   /api/evaluations/compare                 # Confronta presentazioni
POST   /api/evaluations/full-analysis          # Analisi completa
POST   /api/evaluations/batch                  # Valutazioni multiple
GET    /api/evaluations/criteria               # Spiegazione criteri
GET    /api/evaluations/health                 # Health check AI
```

### üîç **Monitoring e Health**
```http
GET    /api/health                             # Health check generale
GET    /api/documents/health                   # Health check RAG
GET    /api/evaluations/health                 # Health check AI
```

## üß™ Testing (in configurazione)

```bash
# Test suite completa (in sviluppo)
npm run test

# Test coverage (in sviluppo)
npm run test:coverage

# Test watch mode (in sviluppo)
npm run test:watch
```

## üì¶ Deployment

### Docker (disponibile)
```bash
# Build immagini
docker-compose build

# Avvia servizi
docker-compose up -d
```

### Produzione (in configurazione)
```bash
# Build ottimizzato (in sviluppo)
npm run build

# Avvia produzione (in sviluppo)
npm run start
```

## üîç Monitoring (in sviluppo)

- **Logs**: Winston con rotazione automatica (in configurazione)
- **Metrics**: Prometheus + Grafana ready (in sviluppo)
- **Health Checks**: `/health` endpoint (in sviluppo)
- **Error Tracking**: Strutturato per Sentry (in sviluppo)

## ü§ù Contribuire

1. Fork il repository
2. Crea feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push branch (`git push origin feature/amazing-feature`)
5. Apri Pull Request

## üìÑ Licenza

Questo progetto √® sotto licenza MIT. Vedi `LICENSE` per dettagli.

## üìà **Aggiornamenti Recenti**

### ‚úÖ **v1.5.0 - Sistema Completamente Operativo** (Settembre 2024)
- **üéØ Whisper Integration**: Configurato e testato OpenAI Whisper locale
- **üîß Automatic Port Management**: Sistema di cleanup automatico porte
- **üé® Enhanced UI**: Interface completa per valutazione con tabs e statistiche
- **üöÄ Real-time Processing**: Visualizzazione backend processing in tempo reale
- **üõ°Ô∏è Security Hardening**: Middleware di sicurezza completo
- **üìä Comprehensive Analytics**: Dashboard statistiche avanzato
- **‚úÖ End-to-End Testing**: Pipeline completa testata e validata

### üéØ **Roadmap Prossimi Aggiornamenti**
- **Database Persistence**: Integrazione PostgreSQL per storage permanente
- **User Management**: Sistema di autenticazione e profili utente
- **Batch Processing**: Valutazione multipla e confronto presentazioni
- **Advanced Analytics**: Metriche di performance e trend analysis
- **Mobile Responsive**: Ottimizzazione completa per dispositivi mobili
- **Docker Deployment**: Container production-ready

## üÜò Supporto

Per problemi o domande:
- Apri un [Issue](https://github.com/simo-hue/AI-RAG-Tutor/issues)
- Consulta la [documentazione](./docs/)
- Contatta il team di sviluppo

### üêõ **Bug Reports**
Quando riporti un bug, includi:
1. **Sistema Operativo**: macOS/Linux/Windows
2. **Versioni**: Node.js, Python, npm
3. **Log Output**: Output dei terminali frontend/backend
4. **Passi per riprodurre**: Sequenza dettagliata del problema
5. **File coinvolti**: Tipi di documenti e formati audio usati
