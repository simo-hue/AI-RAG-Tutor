# AI Speech Evaluator - Sistema di Valutazione Presentazioni ğŸ¯

Un sistema **completamente locale** e **intelligente** di valutazione speech-to-text basato su RAG (Retrieval-Augmented Generation) che analizza presentazioni orali confrontandole **rigorosamente** con documenti di riferimento utilizzando **Ollama**, **Whisper locale** e **rilevamento automatico della lingua**.

**ğŸš€ STATUS: PRODUZIONE-READY** - Sistema completo, testato e ottimizzato con gestione automatica di Ollama, selezione modelli AI e supporto multi-lingua

ğŸ“– **Quick Links:** [ğŸ“‹ Docs Index](./DOCS_INDEX.md) | [ğŸš€ Installation](./INSTALLATION_GUIDE.md) | [ğŸ§ª Testing Guide](./AUDIO_FEATURES_DOCUMENTATION.md#testing) | [ğŸ¤ Contributing](./CONTRIBUTING.md) | [ğŸ“ Changelog](./CHANGELOG.md)

## ğŸ¯ Caratteristiche Uniche

### ğŸ“Š **Valutazione Rigorosa Basata sul Documento**
- âš ï¸ **Zero Conoscenza Esterna**: L'AI valuta SOLO confrontando con il documento caricato
- ğŸ¯ **Accuratezza Rigorosa**: Penalizza automaticamente informazioni non presenti nel documento
- ğŸ“– **FedeltÃ  al Contenuto**: Verifica che la presentazione rifletta esattamente il documento
- ğŸ” **Trasparenza Completa**: Mostra i chunk del documento usati per la valutazione

### ğŸ¤– **Gestione Intelligente Modelli AI**
- âœ… **Selezione Visuale**: Scegli il modello dall'interfaccia grafica
- ğŸ“¥ **Download Automatico**: Se il modello non Ã¨ installato, viene scaricato automaticamente
- ğŸ“Š **Progress Bar Real-time**: Monitora il download con barra di progresso
- ğŸ”„ **Switch Istantaneo**: Cambia modello al volo senza restart
- ğŸ’¡ **Raccomandazioni Smart**: Suggerimenti sui modelli migliori per caso d'uso

### ğŸ™ï¸ **NUOVO: Analisi Audio Avanzata (v2.0.0)** â­
- ğŸ“ˆ **Speech Rate Analysis**: Calcolo WPM (Words Per Minute) con raccomandazioni personalizzate
- â¸ï¸ **Pause Detection**: Analisi pause (brevi/medie/lunghe) e distribuzione ottimale
- ğŸ—£ï¸ **Filler Words Detection**: Rilevamento automatico di 18 filler words italiani (ehm, uhm, cioÃ¨, tipo, ecc.)
- ğŸµ **Audio Quality Metrics**: Analisi volume, pitch variation, e Signal-to-Noise Ratio
- ğŸ† **Speaking Performance Score**: Punteggio complessivo 0-100 con strengths/weaknesses
- ğŸ’¡ **AI-Powered Recommendations**: Suggerimenti specifici per migliorare ogni aspetto
- ğŸ“Š **Beautiful Visualizations**: UI professionale con grafici, gauge e comparison badges
- ğŸ§ª **Production-Ready Testing**: 20+ unit tests, integration tests, E2E tests con Playwright

**[ğŸ“– Documentazione Completa](./AUDIO_FEATURES_DOCUMENTATION.md)** | **[ğŸš€ Installation Guide](./INSTALLATION_GUIDE.md)**

---

[Il resto del README rimane come nella versione precedente, con le aggiunte]


---

## ğŸ¯ **NUOVO: Modelli AI e Valutazioni Rigide (v1.8.0)**

### ğŸ¤– **Gestione Modelli Ollama - Guida Completa**

Il sistema ora offre una gestione completa dei modelli Ollama direttamente dall'interfaccia web.

#### **Modelli Consigliati** (in ordine di preferenza)

1. **llama3.2:3b** ğŸ† (Raccomandato)
   - Dimensione: ~2GB
   - VelocitÃ : âš¡âš¡âš¡ Veloce
   - QualitÃ : â­â­â­â­ Ottima
   - **Perfetto per**: Uso quotidiano, bilanciamento velocitÃ /qualitÃ 
   
2. **llama3.1:8b** ğŸ’ª (Massima QualitÃ )
   - Dimensione: ~4.7GB  
   - VelocitÃ : âš¡âš¡ Medio
   - QualitÃ : â­â­â­â­â­ Eccellente
   - **Perfetto per**: Valutazioni dettagliate, presentazioni importanti

3. **llama3.2:1b** âš¡ (Leggerissimo)
   - Dimensione: ~1.3GB
   - VelocitÃ : âš¡âš¡âš¡âš¡ Ultra veloce
   - QualitÃ : â­â­â­ Buona
   - **Perfetto per**: Test rapidi, hardware limitato

#### **Come Scaricare e Selezionare un Modello**

**Metodo 1: Dall'Interfaccia Web** (Consigliato âœ¨)

1. Vai su `http://localhost:3002/upload`
2. Trova il pannello "Ollama Model Selector" in alto
3. **Se il modello non Ã¨ installato**:
   - Vedrai "âš ï¸ Model llama3.2:3b not available"
   - Clicca il pulsante "Scarica llama3.2:3b"
   - Osserva la progress bar in tempo reale
   - Attendi completamento (2-5 minuti per llama3.2:3b)
4. **Dopo il download**:
   - Il modello apparirÃ  nella lista
   - Click per selezionarlo
   - Vedrai "âœ… llama3.2:3b (Active)"

**Metodo 2: Da Terminale**

```bash
# Scarica modello
ollama pull llama3.2:3b

# Verifica installazione
ollama list

# Output dovrebbe mostrare:
# NAME             ID              SIZE
# llama3.2:3b     a1b2c3d4        2.0 GB
```

#### **Monitoraggio Download**

Durante il download dall'interfaccia vedrai:
```
ğŸ“¥ Downloading llama3.2:3b
Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 65% (1.3 GB / 2.0 GB)
Status: pulling manifest
```

### ğŸ“Š **Sistema di Valutazione Rigorosa - Dettagli**

#### **âš ï¸ Regole CRITICHE di Valutazione**

Il sistema applica prompt **estremamente rigidi** per garantire valutazioni basate **ESCLUSIVAMENTE** sul documento:

```
ğŸ”’ PROMPT DI SISTEMA:
"Sei un valutatore che DEVE usare SOLO le informazioni del documento fornito.
NON usare la tua conoscenza generale.
Se la presentazione menziona argomenti NON nel documento, penalizzala."
```

#### **Esempi Pratici**

**Scenario 1: Presentazione Corretta** âœ…

```
ğŸ“„ Documento Caricato:
"L'intelligenza artificiale Ã¨ una tecnologia che permette ai computer di 
imparare dai dati senza essere esplicitamente programmati."

ğŸ¤ Presentazione Registrata:
"ParlerÃ² dell'intelligenza artificiale, una tecnologia che fa imparare
i computer dai dati senza programmarli esplicitamente."

ğŸ“Š Risultato:
- Accuratezza: 95/100 âœ… (Perfetta corrispondenza)
- Completezza: 90/100 âœ… (Copre tutti i concetti)
- Feedback: "Ottima aderenza al documento. Hai coperto tutti i concetti chiave."
```

**Scenario 2: Informazioni Esterne** âš ï¸

```
ğŸ“„ Documento Caricato:
"L'intelligenza artificiale permette ai computer di imparare dai dati."

ğŸ¤ Presentazione Registrata:
"L'AI fu inventata nel 1956 da John McCarthy al Dartmouth College.
Oggi permette ai computer di imparare dai dati."

ğŸ“Š Risultato:
- Accuratezza: 35/100 âš ï¸ (Include molte info esterne)
- Feedback Dettagliato:
  "âš ï¸ PROBLEMI DI ACCURATEZZA:
  - Hai menzionato '1956' che NON Ã¨ nel documento
  - Hai menzionato 'John McCarthy' che NON Ã¨ nel documento  
  - Hai menzionato 'Dartmouth College' che NON Ã¨ nel documento
  
  âœ… PUNTI CORRETTI:
  - Correttamente menzionato 'imparare dai dati'
  
  ğŸ’¡ SUGGERIMENTO:
  Limita la tua presentazione ai concetti presenti nel documento fornito."
```

#### **Tab "Contesto RAG" - Trasparenza Totale**

Quando visualizzi i risultati, il tab "Contesto RAG" mostra **esattamente** quali parti del documento sono state usate:

```
ğŸ” CHUNK #1 (Rilevanza: 92%)
"L'intelligenza artificiale Ã¨ una tecnologia che permette ai 
computer di imparare dai dati..."
ğŸ“Š Questo chunk Ã¨ stato usato per valutare l'accuratezza

ğŸ” CHUNK #2 (Rilevanza: 78%)
"...senza essere esplicitamente programmati. Gli algoritmi di 
machine learning analizzano..."
ğŸ“Š Questo chunk Ã¨ stato usato per valutare la completezza
```

### ğŸ› **Bug Fixes v1.8.0**

- âœ… **Pulsante Feedback Duplicato**: Rimosso pulsante extra durante registrazione
- âœ… **Lingua Non Visualizzata**: Ora mostra badge "Italian (75%)" dopo upload
- âœ… **Tab Contesto RAG Vuoto**: Risolto, ora mostra correttamente i chunk
- âœ… **Stesso ID Documento/RAG**: Fix critico per matching documento-chunks

### ğŸ”§ **Troubleshooting Aggiuntivo**

#### **Il modello non si scarica**

```bash
# 1. Verifica connessione Ollama
curl http://localhost:11434/api/version

# 2. Verifica spazio disco (servono ~2GB per llama3.2:3b)
df -h ~

# 3. Scarica manualmente
ollama pull llama3.2:3b

# 4. Se fallisce, pulisci e riprova
rm -rf ~/.ollama/models/.tmp
ollama pull llama3.2:3b
```

#### **La valutazione non Ã¨ rigorosa**

Se l'AI sembra usare conoscenza esterna:

1. **Verifica modello**: Usa `llama3.2:3b` o superiore
2. **Controlla i chunk**: Nel tab "Contesto RAG" verifica che siano significativi
3. **Documento troppo corto**: Min. 100 parole per valutazioni accurate
4. **Riavvia Ollama**: A volte aiuta `ollama serve` da terminale

#### **Tab "Contesto RAG" mostra 0 chunk**

```bash
# Verifica che il documento sia stato processato
curl http://localhost:3001/api/documents/<document-id>

# Dovrebbe ritornare:
# { "success": true, "data": { "chunkCount": 3, ... } }

# Se chunkCount Ã¨ 0, ri-carica il documento
```

---

## ğŸ§ª Testing

### Unit Tests

```bash
cd apps/backend
npm test                    # Run all unit tests
npm run test:watch          # Watch mode
npm run test:ui             # Visual UI
npm run test:coverage       # Coverage report
```

### Integration Tests

```bash
cd apps/backend
npm run test:integration    # Run integration tests
```

### E2E Tests (Playwright)

```bash
# From root directory
npm run test:e2e            # Run all E2E tests
npm run test:e2e:ui         # Interactive UI mode
npm run test:e2e:debug      # Debug mode
npm run test:e2e:report     # View HTML report
```

**Coverage Target:** >80% for critical features

ğŸ“– **[Complete Testing Guide](./AUDIO_FEATURES_DOCUMENTATION.md#testing)**

---

## ğŸ“š Documentazione Completa

- **[ğŸ“‹ DOCS_INDEX.md](./DOCS_INDEX.md)** - Indice di tutta la documentazione
- **[ğŸ™ï¸ AUDIO_FEATURES_DOCUMENTATION.md](./AUDIO_FEATURES_DOCUMENTATION.md)** - Guida completa features audio
- **[ğŸš€ INSTALLATION_GUIDE.md](./INSTALLATION_GUIDE.md)** - Installazione dettagliata
- **[ğŸ“ CHANGELOG.md](./CHANGELOG.md)** - Storico versioni e modifiche
- **[ğŸ“Š IMPLEMENTATION_SUMMARY.md](./IMPLEMENTATION_SUMMARY.md)** - Riepilogo implementazione v2.0.0

---

